{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting started with loading CHUV data\n",
    "--------------------------------------\n",
    "\n",
    "In this notebook, you can see examples of how to load some of the CHUV data, such as *dt5*, \n",
    "or *gdp* generated files, or even whole *absd* directory.\n",
    "\n",
    "Requirements:  \n",
    "* having the *__UP2/* data \n",
    "* having set the env variable ``DATA_DIR`` to the above mentioned directory\n",
    "\n",
    "*Author: Etienne de Montalivet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import lighthouse.data_loader.files_folders as ff\n",
    "import lighthouse.metadata as metadata\n",
    "from lighthouse.data_loader.load_chuv import load_absd, load_dt5, load_gdp, load_smr\n",
    "from lighthouse.data_loader.torch_dataset import TimeseriesDataset\n",
    "from lighthouse.preprocessing.transform import MNEFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sessions = metadata.get_training_sessions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP files - stimulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading GDP files for all sessions is still ongoing work which is why we load a specific session here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(os.environ[\"DATA_DIR\"]) / \"__UP2\" / \"0_RAW_DATA\" / \"UP2_001\"\n",
    "(\n",
    "    (stim_data, stim_times, stim_ch_names),\n",
    "    (pred_data, pred_times, pred_ch_names),\n",
    "    (enable_stim_data, enable_stim_times),\n",
    "    lm,\n",
    "    stim_metadata,\n",
    ") = load_gdp(\n",
    "    data_dir\n",
    "    / \"UP2001_2023_11_02_BSITraining_day11\"\n",
    "    / \"GDP\"\n",
    "    / \"Patients\"\n",
    "    / \"Patient_UP2001Rostral\"\n",
    "    / \"Sessions\"\n",
    "    / \"Session_20231102141829\"\n",
    "    / \"GeneralLogs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_data.shape, pred_data.shape, enable_stim_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_ch_names, pred_ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_metadata[\"newElbowExtension\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_stim_data, enable_stim_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smr files - pure hardware data (ecog, trigger, temp, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smr_files = list(Path(training_sessions[0]).glob(\"**/*.smr\"))\n",
    "smr_file = smr_files[0]\n",
    "display(smr_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals, times, ch_names = load_smr(smr_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals.shape, times.shape, ch_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dt5 files - ecog + pred + features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt5_files = list(Path(training_sessions[0]).glob(\"**/*.dt5\"))\n",
    "dt5_file = dt5_files[0]\n",
    "display(dt5_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals, ch_names = load_dt5(dt5_file, return_ch_names=True, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals.shape, ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(signals[ch_names.index(\"is_updating\")])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### absd data (whole folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absd_dirs = [\n",
    "    p.resolve() for p in Path(training_sessions[0]).glob(\"**\") if p.is_dir() and \"ABSD\" in p.name or \"absd\" in p.name\n",
    "]\n",
    "absd_dir = absd_dirs[0]\n",
    "display(absd_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals, ch_names = load_absd(absd_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals.shape, ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(signals[ch_names.index(\"is_updating\")])\n",
    "plt.title(f\"is_updating state\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch dataset with preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use first absd dir of first training session\n",
    "absd_dir = ff.find_absd_dirs(training_sessions[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFREQ = 585\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading functions to be used in the dataset\n",
    "def load_absd_ecog(absd_dir):\n",
    "    signals, ch_names = load_absd(absd_dir)\n",
    "    ecog_ch_names = [ch for ch in ch_names if \"ecog\" in ch]\n",
    "    ecog_signals = signals[[ch_names.index(ch) for ch in ecog_ch_names]]\n",
    "    return ecog_signals\n",
    "\n",
    "\n",
    "def load_absd_states(absd_dir, return_ch_names=False):\n",
    "    signals, ch_names = load_absd(absd_dir, return_states=True)\n",
    "    state_ch_names = [ch for ch in ch_names if \"state__\" in ch]\n",
    "    state_signals = signals[[ch_names.index(ch) for ch in state_ch_names]]\n",
    "    if return_ch_names:\n",
    "        return state_signals, state_ch_names\n",
    "    return state_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, state_ch_names = load_absd_states(absd_dir, return_ch_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size = 585\n",
    "win_step = 59\n",
    "n_fft = win_size\n",
    "hop_length = 10\n",
    "dataset = TimeseriesDataset(\n",
    "    load_x_func=load_absd_ecog,\n",
    "    load_x_args={\"absd_dir\": absd_dir},\n",
    "    load_y_func=load_absd_states,\n",
    "    load_y_args={\"absd_dir\": absd_dir},\n",
    "    n_samples_step=win_step,\n",
    "    n_samples_win=win_size,\n",
    "    x_preprocess=T.Compose(\n",
    "        [\n",
    "            MNEFilter(sfreq=SFREQ, l_freq=1, h_freq=200, notch_freqs=np.arange(50, 201, 50), apply_car=True),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ],\n",
    "    ),\n",
    "    y_preprocess=T.Compose(\n",
    "        [],\n",
    "    ),\n",
    "    x_transform=T.Compose(\n",
    "        [\n",
    "            # we first push to GPU, then apply transforms\n",
    "            lambda x: x.to(DEVICE),\n",
    "            # needs to be adjusted to the desired output size (FREQ_BINS, TIME_BINS)\n",
    "            torchaudio.transforms.Spectrogram(\n",
    "                n_fft=n_fft,\n",
    "                win_length=n_fft,\n",
    "                hop_length=hop_length,\n",
    "                center=True,\n",
    "                window_fn=lambda x: torch.hann_window(x).to(DEVICE),\n",
    "            ),\n",
    "            lambda x: x.squeeze(0).float(),\n",
    "        ]\n",
    "    ),\n",
    "    y_transform=T.Compose(\n",
    "        [\n",
    "            lambda x: torch.tensor(x).to(DEVICE),\n",
    "            # for the sake of this example, we take the last state value\n",
    "            lambda x: x[..., -1].flatten().float(),\n",
    "        ]\n",
    "    ),\n",
    "    precompute=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
